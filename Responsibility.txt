Responsibilities:
•	Analyzing the requirement to setup a cluster.
•	Prepared Design document specifications.
•	Moved all log files generated by various network devices into HDFS location.
•	Developed the sqoop scripts in order to make the interaction between Pig and MySQL Database.
•	 Involved in developing the Pig scripts. 
•	 Involved in creating the External Hive Table on top of analyzed data.
•	 Prepared Unit Test documents and code review documents.

?	Installing Hadoop and Setting up Hadoop cluster.
?	Working as HDFS and hadoop map reduce admin
?	Loading files to HDFS and writing map reduce jobs to mine the data.
?	Understanding and tacking backup of Data node, Name node, Job Tracker, Secondary Name node, Task Tracker.
?	Troubleshoot map reduce jobs, PIG scripts and HIVE queries.
?	Involved in Commissioning and decommissioning the Name node
?	Hadoop Shell commands, Writing Map reduce Programs, Verifying the Hadoop Log Files
?	Well understanding of HDFS and Map Reduce framework and Hadoop's ecosystem 
?	Writing pig Scripts & loading data to Hive tables.
?	Created Technical design documents based on business process requirements.
?	Involved in the debugging of the coding.
